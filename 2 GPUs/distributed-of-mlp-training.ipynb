{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30823,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# DDP with Model Parallelism ","metadata":{}},{"cell_type":"code","source":"%%writefile main.py\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nimport torch.utils.data as data\n\nimport torchvision.transforms as transforms\nimport torchvision.datasets as datasets\n\nfrom sklearn import metrics\nfrom sklearn import decomposition\nfrom sklearn import manifold\nfrom tqdm.notebook import trange, tqdm\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n\nimport copy\nimport random\nimport time\nimport os\nimport json\n\nfrom torch.utils.data.distributed import DistributedSampler\nfrom torch.nn.parallel import DistributedDataParallel as DDP\nimport torch.distributed as dist\nimport torch.multiprocessing as mp\n\nSEED = 1234\nROOT = \".\"\nMODEL_NAME = \"MLP\"\nSENARIO = \"2GPU\"\nEPOCHS = 10\nBATCH_SIZE = 512\n\noutdir = \"./my_datasets\"  \nos.makedirs(outdir, exist_ok=True)\nos.environ['HF_DATASETS_CACHE'] = outdir\n\n\nrandom.seed(SEED)\nnp.random.seed(SEED)\ntorch.manual_seed(SEED)\ntorch.cuda.manual_seed(SEED)\ntorch.backends.cudnn.deterministic = True\n\n\"\"\"# 2. Initialize the DDP Environment\"\"\"\n\ndef setup(rank, world_size):\n    os.environ['MASTER_ADDR'] = 'localhost'  # Change this to the master node's IP address if using multiple machines\n    os.environ['MASTER_PORT'] = '12345'  # Pick a free port on the master node\n    dist.init_process_group(\"nccl\", rank=rank, world_size=world_size)\n\ndef cleanup():\n    dist.destroy_process_group()\n\n\"\"\"# 3. Define a Model.\"\"\"\n\nclass MLP(nn.Module):\n    def __init__(self, input_dim, output_dim, dev0, dev1):\n        super().__init__()\n        self.dev0 = dev0\n        self.dev1 = dev1\n\n        self.input_fc = nn.Linear(input_dim, 250).to(dev0)\n        self.hidden_fc = nn.Linear(250, 100).to(dev1)\n        self.output_fc = nn.Linear(100, output_dim).to(dev1)\n\n    def forward(self, x):\n\n        # x = [batch size, height, width]\n\n        batch_size = x.shape[0]\n\n        x = x.view(batch_size, -1)\n        x = x.to(self.dev0)\n\n        # x = [batch size, height * width]\n\n        h_1 = F.relu(self.input_fc(x))\n        h_1 = h_1.to(self.dev1)\n\n        # h_1 = [batch size, 250]\n\n        h_2 = F.relu(self.hidden_fc(h_1))\n\n        # h_2 = [batch size, 100]\n\n        y_pred = self.output_fc(h_2)\n\n        # y_pred = [batch size, output dim]\n\n        return y_pred, h_2\n\n\n\ndef count_parameters(model):\n    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n\ndef create_model(dev0, dev1):\n    INPUT_DIM = 28 * 28\n    OUTPUT_DIM = 10\n\n    model = MLP(INPUT_DIM, OUTPUT_DIM, dev0, dev1)\n    print(f'The model has {count_parameters(model):,} trainable parameters')\n\n    return model\n\n\"\"\"# 4. Create a Dummy Dataset\"\"\"\n\ndef create_dataloader(rank, world_size, batch_size=BATCH_SIZE, root = ROOT, max_length = 256):\n    mean = 0.13066047430038452\n    std = 0.30810779333114624\n\n    train_transforms = transforms.Compose([\n                            transforms.RandomRotation(5, fill=(0,)),\n                            transforms.RandomCrop(28, padding=2),\n                            transforms.ToTensor(),\n                            transforms.Normalize(mean=[mean], std=[std])\n                                      ])\n\n    test_transforms = transforms.Compose([\n                           transforms.ToTensor(),\n                           transforms.Normalize(mean=[mean], std=[std])\n                                     ])\n\n    ## load the data with\n    outdir = f\"{root}/data\"\n    if rank == 0 and not os.path.exists(outdir):\n        train_data = datasets.MNIST(root=outdir,\n                                    train=True,\n                                    download=True,\n                                    transform=train_transforms)\n\n        test_data = datasets.MNIST(root=outdir,\n                                  train=False,\n                                  download=True,\n                                  transform=test_transforms)\n\n    dist.barrier()  # Ensure all processes wait for the dataset to be downloaded\n     \n    train_data = datasets.MNIST(root=outdir,\n                                train=True,\n                                download=True,\n                                transform=train_transforms)\n\n    test_data = datasets.MNIST(root=outdir,\n                              train=False,\n                              download=True,\n                              transform=test_transforms)\n    \n\n    ## create the validation split\n    VALID_RATIO = 0.9\n\n    n_train_examples = int(len(train_data) * VALID_RATIO)\n    n_valid_examples = len(train_data) - n_train_examples\n    train_data, valid_data = data.random_split(train_data,\n                                           [n_train_examples, n_valid_examples])\n\n    if rank == 0:\n        print(f'Number of training examples: {len(train_data)}')\n        print(f'Number of validation examples: {len(valid_data)}')\n        print(f'Number of testing examples: {len(test_data)}')\n\n\n    ## Creating Data Loaders\n    \n    train_sampler = DistributedSampler(train_data, num_replicas=world_size, rank=rank, shuffle=True)\n    val_sampler = DistributedSampler(valid_data, num_replicas=world_size, rank=rank)\n\n    train_dataloader = data.DataLoader(train_data, batch_size=batch_size, sampler=train_sampler, pin_memory=True) #use num_workers > 0 for better performance\n    val_dataloader = data.DataLoader(valid_data, batch_size=batch_size, sampler=val_sampler, pin_memory=True) #use num_workers > 0 for better performance\n    test_dataloader = data.DataLoader(test_data, batch_size=batch_size, shuffle=False, pin_memory=True) #no sampling for test dataset\n    return train_dataloader, val_dataloader, test_dataloader\n\n\"\"\"# 5. Implement the Training Loop\n\n## a. Help function\n\"\"\"\n\nRESULTS_FILE = f\"{ROOT}/{MODEL_NAME}_{EPOCHS}epochs_{SENARIO}.json\"\n\ndef log_results(scenario, results):\n    \"\"\"\n    Save results to a JSON file for comparison across scenarios.\n    \"\"\"\n    if os.path.exists(RESULTS_FILE):\n        with open(RESULTS_FILE, 'r') as f:\n            all_results = json.load(f)\n    else:\n        all_results = {}\n\n    all_results[scenario] = results\n\n    with open(RESULTS_FILE, 'w') as f:\n        json.dump(all_results, f, indent=4)\n\ndef calculate_accuracy(y_pred, y):\n    top_pred = y_pred.argmax(1, keepdim=True)\n    correct = top_pred.eq(y.view_as(top_pred)).sum()\n    acc = correct.float() / y.shape[0]\n    return acc\n\ndef epoch_time(start_time, end_time):\n    elapsed_time = end_time - start_time\n    elapsed_mins = int(elapsed_time / 60)\n    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n    return elapsed_mins, elapsed_secs\n\n\"\"\"## b. train function\"\"\"\ndef train(model, iterator, optimizer, criterion, dev0, dev1):\n\n    epoch_loss = 0\n    epoch_acc = 0\n\n    model.train()\n    i=0\n    for (x, y) in tqdm(iterator, desc=f\"Training on the dev0 {dev0} & dev1 {dev1}...\", leave=False):\n\n        x = x.to(dev0)\n        y = y.to(dev1)\n\n        optimizer.zero_grad()\n\n        y_pred, _ = model(x)\n\n        loss = criterion(y_pred, y)\n\n        acc = calculate_accuracy(y_pred, y)\n\n        loss.backward()\n\n        optimizer.step()\n\n        epoch_loss += loss.item()\n        epoch_acc += acc.item()\n        if i % 50 == 0 and dev0*dev1 == 0 :\n            print(f\"- On Training: {i} was passed over  {len(iterator)}\")\n        i+=1\n\n    return epoch_loss / len(iterator), epoch_acc / len(iterator)\n \n\n\"\"\"## c. Validation function\"\"\"\ndef evaluate(model, iterator, criterion, dev0, dev1, mode = \"Evaluating\"):\n\n    epoch_loss = 0\n    epoch_acc = 0\n\n    model.eval()\n    i=0\n    with torch.no_grad():\n\n        for (x, y) in tqdm(iterator, desc=f\"{mode} on the dev0 {dev0} & dev1 {dev1}...\", leave=False):\n\n            x = x.to(dev0)\n            y = y.to(dev1)\n\n            y_pred, _ = model(x)\n\n            loss = criterion(y_pred, y)\n\n            acc = calculate_accuracy(y_pred, y)\n\n            epoch_loss += loss.item()\n            epoch_acc += acc.item()\n\n            if i % 50 == 0 and dev0*dev1 == 0:\n                print(f\"- On {mode}: {i} was passed over  {len(iterator)}\")\n            i+=1\n\n    return epoch_loss / len(iterator), epoch_acc / len(iterator)\n\n\n\"\"\"## d. Main loop\"\"\"\n\noutdir = f'{ROOT}/model/'\nif not os.path.exists(outdir):\n    os.makedirs(outdir)\n\ndef main_train(rank, world_size, root = outdir, num_epochs = EPOCHS, model_name = MODEL_NAME):\n    ## a. Set up the distributed process groups\n    setup(rank, world_size)\n    print(f\"Process {rank} initialized.\")\n\n    # setup mp_model and devices for this process\n    dev0 = rank * 2\n    dev1 = rank * 2 + 1\n\n    ## b. Create Model, DataLoader\n    train_dataloader, val_dataloader, test_dataloader = create_dataloader(rank, world_size)\n    model = create_model(dev0, dev1)\n\n    ## c. Wrap the model with DistributedDataParallel\n    ddp_model = DDP(model)\n\n    ## d. Loss and Optimizer\n    #LR = 5e-4\n    criterion = nn.CrossEntropyLoss() # Move loss to GPU\n    optimizer = optim.Adam(ddp_model.parameters())\n\n    ## e. Training Loop\n    best_valid_loss = float('inf')\n    training_times = []\n    train_losses = []\n    train_accurcy = []\n    validation_times = []\n    validation_losses = []\n    validation_accurcy = []\n\n    epoch_times = []\n    \n    for epoch in trange(num_epochs, desc=\"Epochs\"):\n        start_epoch_time = time.monotonic()\n        start_time = time.monotonic()\n\n        train_loss, train_acc = train(ddp_model, train_dataloader, optimizer, criterion, dev0, dev1)\n        train_time = time.monotonic() - start_time\n        training_times.append(train_time)\n        train_losses.append(train_loss)\n        train_accurcy.append(train_acc)\n\n        start_time = time.monotonic()\n        valid_loss, valid_acc = evaluate(ddp_model, val_dataloader, criterion, dev0, dev1)\n        val_time = time.monotonic() - start_time\n        validation_times.append(val_time)\n        validation_losses.append(valid_loss)\n        validation_accurcy.append(valid_acc)\n\n        if valid_loss < best_valid_loss:\n            best_valid_loss = valid_loss\n            torch.save(ddp_model.state_dict(), f'{root}mlp-model.pt')\n\n        end_time = time.monotonic()\n        e_time = end_time - start_epoch_time\n        epoch_times.append(e_time)\n        epoch_mins, epoch_secs = epoch_time(start_epoch_time, end_time)\n\n        print(f'--------------|     On process {rank}      |----------------')\n        print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n        print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n        print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')\n\n    ## f. test after train\n    ddp_model.load_state_dict(torch.load(f'{root}mlp-model.pt'))\n    start_time = time.monotonic()\n    test_loss, test_acc = evaluate(ddp_model, test_dataloader, criterion, dev0, dev1, mode = \"Testing\")\n    test_time = time.monotonic() - start_time\n    print(f'Test results on process {rank}: Test Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}%')\n\n    # Log results\n    results = {\n        \"world_size\": world_size,\n        \"rank\": rank,\n        \"training_times\": training_times,\n        \"train_losses\": train_losses,\n        \"train_accurcy\": train_accurcy,\n        \"validation_times\": validation_times,\n        \"validation_losses\": validation_losses,\n        \"validation_accurcy\": validation_accurcy,\n        \"test_time\": test_time,\n        \"test_loss\": test_loss,\n        \"test_acc\": test_acc,\n        \"epoch_times\": epoch_times\n     }\n\n    scenario = f\"model_{model_name}_epochs_{num_epochs}_{world_size}_GPUs_dev0_{dev0}_dev1_{dev1}_rank_{0}\"\n    log_results(scenario, results)\n    dist.barrier()\n    \n    cleanup()\n    print(f'Process {rank} finished training.')\n\n\"\"\"# 6. Main Execution\"\"\"\nif __name__ == \"__main__\":\n\n    def main():\n        world_size = torch.cuda.device_count()\n        print(f'Total number of devices detected: {world_size}')\n\n        if world_size >= 1:\n            #start the training process on all available GPUs\n            world_size = world_size//2\n            if world_size > 1:\n                #start the training process on all available GPUs\n                \n                mp.spawn(\n                    main_train,\n                    args=(world_size,),\n                    nprocs=world_size,\n                    join=True\n                )\n            else:\n                #run training on single GPU\n                main_train(rank=0, world_size=world_size)\n\n        else:\n            print('no GPUs found. Please make sure you have configured CUDA correctly')\n\n    main()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-09T00:14:01.086779Z","iopub.execute_input":"2025-01-09T00:14:01.087068Z","iopub.status.idle":"2025-01-09T00:14:01.094592Z","shell.execute_reply.started":"2025-01-09T00:14:01.087047Z","shell.execute_reply":"2025-01-09T00:14:01.093756Z"}},"outputs":[{"name":"stdout","text":"Overwriting main.py\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"!python main.py","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-09T00:14:04.594764Z","iopub.execute_input":"2025-01-09T00:14:04.595130Z","iopub.status.idle":"2025-01-09T00:17:57.777456Z","shell.execute_reply.started":"2025-01-09T00:14:04.595091Z","shell.execute_reply":"2025-01-09T00:17:57.776645Z"}},"outputs":[{"name":"stdout","text":"Total number of devices detected: 2\nProcess 0 initialized.\nDownloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\nFailed to download (trying next):\nHTTP Error 403: Forbidden\n\nDownloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\nDownloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n100%|███████████████████████████| 9912422/9912422 [00:00<00:00, 43517733.63it/s]\nExtracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n\nDownloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\nFailed to download (trying next):\nHTTP Error 403: Forbidden\n\nDownloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\nDownloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n100%|████████████████████████████████| 28881/28881 [00:00<00:00, 1146749.09it/s]\nExtracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n\nDownloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\nFailed to download (trying next):\nHTTP Error 403: Forbidden\n\nDownloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\nDownloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n100%|███████████████████████████| 1648877/1648877 [00:00<00:00, 10585051.21it/s]\nExtracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n\nDownloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\nFailed to download (trying next):\nHTTP Error 403: Forbidden\n\nDownloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\nDownloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n100%|█████████████████████████████████| 4542/4542 [00:00<00:00, 20752209.99it/s]\nExtracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n\nNumber of training examples: 54000\nNumber of validation examples: 6000\nNumber of testing examples: 10000\nThe model has 222,360 trainable parameters\nEpochs:   0%|          | 0/10 [00:00<?, ?it/s]\nTraining on the dev0 0 & dev1 1...:   0%|          | 0/106 [00:00<?, ?it/s]\n- On Training: 0 was passed over  106\n[rank0]:[W109 00:14:14.966953704 logger.cpp:330] Warning: Cuda time stats are not collected for multi-device modules. (function operator())\n- On Training: 50 was passed over  106\n- On Training: 100 was passed over  106\nEvaluating on the dev0 0 & dev1 1...:   0%|          | 0/12 [00:00<?, ?it/s]\n- On Evaluating: 0 was passed over  12\n--------------|     On process 0      |----------------\nEpoch: 01 | Epoch Time: 0m 22s\n\tTrain Loss: 0.792 | Train Acc: 75.82%\n\t Val. Loss: 0.414 |  Val. Acc: 87.49%\nTraining on the dev0 0 & dev1 1...:   0%|          | 0/106 [00:00<?, ?it/s]\n- On Training: 0 was passed over  106\n- On Training: 50 was passed over  106\n- On Training: 100 was passed over  106\nEvaluating on the dev0 0 & dev1 1...:   0%|          | 0/12 [00:00<?, ?it/s]\n- On Evaluating: 0 was passed over  12\n--------------|     On process 0      |----------------\nEpoch: 02 | Epoch Time: 0m 22s\n\tTrain Loss: 0.297 | Train Acc: 91.10%\n\t Val. Loss: 0.257 |  Val. Acc: 92.55%\nTraining on the dev0 0 & dev1 1...:   0%|          | 0/106 [00:00<?, ?it/s]\n- On Training: 0 was passed over  106\n- On Training: 50 was passed over  106\n- On Training: 100 was passed over  106\nEvaluating on the dev0 0 & dev1 1...:   0%|          | 0/12 [00:00<?, ?it/s]\n- On Evaluating: 0 was passed over  12\n--------------|     On process 0      |----------------\nEpoch: 03 | Epoch Time: 0m 22s\n\tTrain Loss: 0.206 | Train Acc: 93.91%\n\t Val. Loss: 0.197 |  Val. Acc: 94.43%\nTraining on the dev0 0 & dev1 1...:   0%|          | 0/106 [00:00<?, ?it/s]\n- On Training: 0 was passed over  106\n- On Training: 50 was passed over  106\n- On Training: 100 was passed over  106\nEvaluating on the dev0 0 & dev1 1...:   0%|          | 0/12 [00:00<?, ?it/s]\n- On Evaluating: 0 was passed over  12\n--------------|     On process 0      |----------------\nEpoch: 04 | Epoch Time: 0m 21s\n\tTrain Loss: 0.166 | Train Acc: 95.01%\n\t Val. Loss: 0.177 |  Val. Acc: 94.39%\nTraining on the dev0 0 & dev1 1...:   0%|          | 0/106 [00:00<?, ?it/s]\n- On Training: 0 was passed over  106\n- On Training: 50 was passed over  106\n- On Training: 100 was passed over  106\nEvaluating on the dev0 0 & dev1 1...:   0%|          | 0/12 [00:00<?, ?it/s]\n- On Evaluating: 0 was passed over  12\n--------------|     On process 0      |----------------\nEpoch: 05 | Epoch Time: 0m 21s\n\tTrain Loss: 0.146 | Train Acc: 95.52%\n\t Val. Loss: 0.149 |  Val. Acc: 95.54%\nTraining on the dev0 0 & dev1 1...:   0%|          | 0/106 [00:00<?, ?it/s]\n- On Training: 0 was passed over  106\n- On Training: 50 was passed over  106\n- On Training: 100 was passed over  106\nEvaluating on the dev0 0 & dev1 1...:   0%|          | 0/12 [00:00<?, ?it/s]\n- On Evaluating: 0 was passed over  12\n--------------|     On process 0      |----------------\nEpoch: 06 | Epoch Time: 0m 21s\n\tTrain Loss: 0.129 | Train Acc: 96.08%\n\t Val. Loss: 0.139 |  Val. Acc: 95.51%\nTraining on the dev0 0 & dev1 1...:   0%|          | 0/106 [00:00<?, ?it/s]\n- On Training: 0 was passed over  106\n- On Training: 50 was passed over  106\n- On Training: 100 was passed over  106\nEvaluating on the dev0 0 & dev1 1...:   0%|          | 0/12 [00:00<?, ?it/s]\n- On Evaluating: 0 was passed over  12\n--------------|     On process 0      |----------------\nEpoch: 07 | Epoch Time: 0m 21s\n\tTrain Loss: 0.117 | Train Acc: 96.45%\n\t Val. Loss: 0.136 |  Val. Acc: 95.97%\nTraining on the dev0 0 & dev1 1...:   0%|          | 0/106 [00:00<?, ?it/s]\n- On Training: 0 was passed over  106\n- On Training: 50 was passed over  106\n- On Training: 100 was passed over  106\nEvaluating on the dev0 0 & dev1 1...:   0%|          | 0/12 [00:00<?, ?it/s]\n- On Evaluating: 0 was passed over  12\n--------------|     On process 0      |----------------\nEpoch: 08 | Epoch Time: 0m 22s\n\tTrain Loss: 0.109 | Train Acc: 96.53%\n\t Val. Loss: 0.123 |  Val. Acc: 96.17%\nTraining on the dev0 0 & dev1 1...:   0%|          | 0/106 [00:00<?, ?it/s]\n- On Training: 0 was passed over  106\n- On Training: 50 was passed over  106\n- On Training: 100 was passed over  106\nEvaluating on the dev0 0 & dev1 1...:   0%|          | 0/12 [00:00<?, ?it/s]\n- On Evaluating: 0 was passed over  12\n--------------|     On process 0      |----------------\nEpoch: 09 | Epoch Time: 0m 21s\n\tTrain Loss: 0.099 | Train Acc: 96.87%\n\t Val. Loss: 0.106 |  Val. Acc: 96.90%\nTraining on the dev0 0 & dev1 1...:   0%|          | 0/106 [00:00<?, ?it/s]\n- On Training: 0 was passed over  106\n- On Training: 50 was passed over  106\n- On Training: 100 was passed over  106\nEvaluating on the dev0 0 & dev1 1...:   0%|          | 0/12 [00:00<?, ?it/s]\n- On Evaluating: 0 was passed over  12\n--------------|     On process 0      |----------------\nEpoch: 10 | Epoch Time: 0m 21s\n\tTrain Loss: 0.095 | Train Acc: 97.04%\n\t Val. Loss: 0.111 |  Val. Acc: 96.78%\n/kaggle/working/main.py:347: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  ddp_model.load_state_dict(torch.load(f'{root}mlp-model.pt'))\nTesting on the dev0 0 & dev1 1...:   0%|          | 0/20 [00:00<?, ?it/s]\n- On Testing: 0 was passed over  20\nTest results on process 0: Test Loss: 0.066 | Test Acc: 98.06%\nProcess 0 finished training.\n","output_type":"stream"}],"execution_count":6},{"cell_type":"markdown","source":"# DDP","metadata":{}},{"cell_type":"code","source":"%%writefile main.py\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nimport torch.utils.data as data\n\nimport torchvision.transforms as transforms\nimport torchvision.datasets as datasets\n\nfrom sklearn import metrics\nfrom sklearn import decomposition\nfrom sklearn import manifold\nfrom tqdm.notebook import trange, tqdm\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n\nimport copy\nimport random\nimport time\nimport os\nimport json\n\nfrom torch.utils.data.distributed import DistributedSampler\nfrom torch.nn.parallel import DistributedDataParallel as DDP\nimport torch.distributed as dist\nimport torch.multiprocessing as mp\n\nSEED = 1234\nROOT = \".\"\nMODEL_NAME = \"MLP\"\nSENARIO = \"2GPU_DDP\"\nEPOCHS = 10\nBATCH_SIZE = 512\n\noutdir = \"./my_datasets\"  \nos.makedirs(outdir, exist_ok=True)\nos.environ['HF_DATASETS_CACHE'] = outdir\n\n\nrandom.seed(SEED)\nnp.random.seed(SEED)\ntorch.manual_seed(SEED)\ntorch.cuda.manual_seed(SEED)\ntorch.backends.cudnn.deterministic = True\n\n\"\"\"# 2. Initialize the DDP Environment\"\"\"\n\ndef setup(rank, world_size):\n    os.environ['MASTER_ADDR'] = 'localhost'  # Change this to the master node's IP address if using multiple machines\n    os.environ['MASTER_PORT'] = '12345'  # Pick a free port on the master node\n    dist.init_process_group(\"nccl\", rank=rank, world_size=world_size)\n\ndef cleanup():\n    dist.destroy_process_group()\n\n\"\"\"# 3. Define a Model.\"\"\"\n\nclass MLP(nn.Module):\n    def __init__(self, input_dim, output_dim):\n        super().__init__()\n\n        self.input_fc = nn.Linear(input_dim, 250)\n        self.hidden_fc = nn.Linear(250, 100)\n        self.output_fc = nn.Linear(100, output_dim)\n\n    def forward(self, x):\n\n        # x = [batch size, height, width]\n\n        batch_size = x.shape[0]\n\n        x = x.view(batch_size, -1)\n\n        # x = [batch size, height * width]\n\n        h_1 = F.relu(self.input_fc(x))\n\n        # h_1 = [batch size, 250]\n\n        h_2 = F.relu(self.hidden_fc(h_1))\n\n        # h_2 = [batch size, 100]\n\n        y_pred = self.output_fc(h_2)\n\n        # y_pred = [batch size, output dim]\n\n        return y_pred, h_2\n\n\n\ndef count_parameters(model):\n    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n\ndef create_model():\n    INPUT_DIM = 28 * 28\n    OUTPUT_DIM = 10\n\n    model = MLP(INPUT_DIM, OUTPUT_DIM)\n    print(f'The model has {count_parameters(model):,} trainable parameters')\n\n    return model\n\n\"\"\"# 4. Create a Dummy Dataset\"\"\"\n\ndef create_dataloader(rank, world_size, batch_size=BATCH_SIZE, root = ROOT, max_length = 256):\n    mean = 0.13066047430038452\n    std = 0.30810779333114624\n\n    train_transforms = transforms.Compose([\n                            transforms.RandomRotation(5, fill=(0,)),\n                            transforms.RandomCrop(28, padding=2),\n                            transforms.ToTensor(),\n                            transforms.Normalize(mean=[mean], std=[std])\n                                      ])\n\n    test_transforms = transforms.Compose([\n                           transforms.ToTensor(),\n                           transforms.Normalize(mean=[mean], std=[std])\n                                     ])\n\n    ## load the data with\n    outdir = f\"{root}/data\"\n    if rank == 0 and not os.path.exists(outdir):\n        train_data = datasets.MNIST(root=outdir,\n                                    train=True,\n                                    download=True,\n                                    transform=train_transforms)\n\n        test_data = datasets.MNIST(root=outdir,\n                                  train=False,\n                                  download=True,\n                                  transform=test_transforms)\n\n    dist.barrier()  # Ensure all processes wait for the dataset to be downloaded\n     \n    train_data = datasets.MNIST(root=outdir,\n                                train=True,\n                                download=True,\n                                transform=train_transforms)\n\n    test_data = datasets.MNIST(root=outdir,\n                              train=False,\n                              download=True,\n                              transform=test_transforms)\n    \n\n    ## create the validation split\n    VALID_RATIO = 0.9\n\n    n_train_examples = int(len(train_data) * VALID_RATIO)\n    n_valid_examples = len(train_data) - n_train_examples\n    train_data, valid_data = data.random_split(train_data,\n                                           [n_train_examples, n_valid_examples])\n\n    if rank == 0:\n        print(f'Number of training examples: {len(train_data)}')\n        print(f'Number of validation examples: {len(valid_data)}')\n        print(f'Number of testing examples: {len(test_data)}')\n\n\n    ## Creating Data Loaders\n    \n    train_sampler = DistributedSampler(train_data, num_replicas=world_size, rank=rank, shuffle=True)\n    val_sampler = DistributedSampler(valid_data, num_replicas=world_size, rank=rank)\n\n    train_dataloader = data.DataLoader(train_data, batch_size=batch_size, sampler=train_sampler, pin_memory=True) #use num_workers > 0 for better performance\n    val_dataloader = data.DataLoader(valid_data, batch_size=batch_size, sampler=val_sampler, pin_memory=True) #use num_workers > 0 for better performance\n    test_dataloader = data.DataLoader(test_data, batch_size=batch_size, shuffle=False, pin_memory=True) #no sampling for test dataset\n    return train_dataloader, val_dataloader, test_dataloader\n\n\"\"\"# 5. Implement the Training Loop\n\n## a. Help function\n\"\"\"\n\nRESULTS_FILE = f\"{ROOT}/{MODEL_NAME}_{EPOCHS}epochs_{SENARIO}.json\"\n\ndef log_results(scenario, results):\n    \"\"\"\n    Save results to a JSON file for comparison across scenarios.\n    \"\"\"\n    if os.path.exists(RESULTS_FILE):\n        with open(RESULTS_FILE, 'r') as f:\n            all_results = json.load(f)\n    else:\n        all_results = {}\n\n    all_results[scenario] = results\n\n    with open(RESULTS_FILE, 'w') as f:\n        json.dump(all_results, f, indent=4)\n\ndef calculate_accuracy(y_pred, y):\n    top_pred = y_pred.argmax(1, keepdim=True)\n    correct = top_pred.eq(y.view_as(top_pred)).sum()\n    acc = correct.float() / y.shape[0]\n    return acc\n\ndef epoch_time(start_time, end_time):\n    elapsed_time = end_time - start_time\n    elapsed_mins = int(elapsed_time / 60)\n    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n    return elapsed_mins, elapsed_secs\n\n\"\"\"## b. train function\"\"\"\ndef train(model, iterator, optimizer, criterion, rank):\n\n    epoch_loss = 0\n    epoch_acc = 0\n\n    model.train()\n    i=0\n    for (x, y) in tqdm(iterator, desc=f\"Training on the rank {rank}...\", leave=False):\n\n        x = x.to(rank)\n        y = y.to(rank)\n\n        optimizer.zero_grad()\n\n        y_pred, _ = model(x)\n\n        loss = criterion(y_pred, y)\n\n        acc = calculate_accuracy(y_pred, y)\n\n        loss.backward()\n\n        optimizer.step()\n\n        epoch_loss += loss.item()\n        epoch_acc += acc.item()\n        if i % 50 == 0 and rank == 0 :\n            print(f\"- On Training: {i} was passed over  {len(iterator)}\")\n        i+=1\n\n    return epoch_loss / len(iterator), epoch_acc / len(iterator)\n \n\n\"\"\"## c. Validation function\"\"\"\ndef evaluate(model, iterator, criterion, rank, mode = \"Evaluating\"):\n\n    epoch_loss = 0\n    epoch_acc = 0\n\n    model.eval()\n    i=0\n    with torch.no_grad():\n\n        for (x, y) in tqdm(iterator, desc=f\"{mode} on the rank {rank} ...\", leave=False):\n\n            x = x.to(rank)\n            y = y.to(rank)\n\n            y_pred, _ = model(x)\n\n            loss = criterion(y_pred, y)\n\n            acc = calculate_accuracy(y_pred, y)\n\n            epoch_loss += loss.item()\n            epoch_acc += acc.item()\n\n            if i % 50 == 0 and rank == 0:\n                print(f\"- On {mode}: {i} was passed over  {len(iterator)}\")\n            i+=1\n\n    return epoch_loss / len(iterator), epoch_acc / len(iterator)\n\n\n\"\"\"## d. Main loop\"\"\"\n\noutdir = f'{ROOT}/model/'\nif not os.path.exists(outdir):\n    os.makedirs(outdir)\n\ndef main_train(rank, world_size, root = outdir, num_epochs = EPOCHS, model_name = MODEL_NAME):\n    ## a. Set up the distributed process groups\n    setup(rank, world_size)\n    print(f\"Process {rank} initialized.\")\n\n    # setup mp_model and devices for this process\n    \n\n    ## b. Create Model, DataLoader\n    train_dataloader, val_dataloader, test_dataloader = create_dataloader(rank, world_size)\n    model = create_model().to(rank)\n\n    ## c. Wrap the model with DistributedDataParallel\n    ddp_model = DDP(model, device_ids=[rank])\n\n    ## d. Loss and Optimizer\n    #LR = 5e-4\n    criterion = nn.CrossEntropyLoss().to(rank) # Move loss to GPU\n    optimizer = optim.Adam(ddp_model.parameters())\n\n    ## e. Training Loop\n    best_valid_loss = float('inf')\n    training_times = []\n    train_losses = []\n    train_accurcy = []\n    validation_times = []\n    validation_losses = []\n    validation_accurcy = []\n\n    epoch_times = []\n    \n    for epoch in trange(num_epochs, desc=\"Epochs\"):\n        start_epoch_time = time.monotonic()\n        start_time = time.monotonic()\n\n        train_loss, train_acc = train(ddp_model, train_dataloader, optimizer, criterion, rank)\n        train_time = time.monotonic() - start_time\n        training_times.append(train_time)\n        train_losses.append(train_loss)\n        train_accurcy.append(train_acc)\n\n        start_time = time.monotonic()\n        valid_loss, valid_acc = evaluate(ddp_model, val_dataloader, criterion, rank)\n        val_time = time.monotonic() - start_time\n        validation_times.append(val_time)\n        validation_losses.append(valid_loss)\n        validation_accurcy.append(valid_acc)\n\n        if valid_loss < best_valid_loss:\n            best_valid_loss = valid_loss\n            torch.save(ddp_model.state_dict(), f'{root}mlp-model.pt')\n\n        end_time = time.monotonic()\n        e_time = end_time - start_epoch_time\n        epoch_times.append(e_time)\n        epoch_mins, epoch_secs = epoch_time(start_epoch_time, end_time)\n\n        print(f'--------------|     On process {rank}      |----------------')\n        print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n        print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n        print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')\n\n    ## f. test after train\n    ddp_model.load_state_dict(torch.load(f'{root}mlp-model.pt'))\n    start_time = time.monotonic()\n    test_loss, test_acc = evaluate(ddp_model, test_dataloader, criterion, rank, mode = \"Testing\")\n    test_time = time.monotonic() - start_time\n    print(f'Test results on process {rank}: Test Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}%')\n\n    # Log results\n    results = {\n        \"world_size\": world_size,\n        \"rank\": rank,\n        \"training_times\": training_times,\n        \"train_losses\": train_losses,\n        \"train_accurcy\": train_accurcy,\n        \"validation_times\": validation_times,\n        \"validation_losses\": validation_losses,\n        \"validation_accurcy\": validation_accurcy,\n        \"test_time\": test_time,\n        \"test_loss\": test_loss,\n        \"test_acc\": test_acc,\n        \"epoch_times\": epoch_times\n     }\n\n    scenario = f\"model_{model_name}_epochs_{num_epochs}_{world_size}_GPUs_rank_{rank}\"\n    log_results(scenario, results)\n    dist.barrier()\n    \n    cleanup()\n    print(f'Process {rank} finished training.')\n\n\"\"\"# 6. Main Execution\"\"\"\nif __name__ == \"__main__\":\n\n    def main():\n        world_size = torch.cuda.device_count()\n        print(f'Total number of devices detected: {world_size}')\n\n        if world_size >= 1:\n            #start the training process on all available GPUs\n            \n            if world_size > 1:\n                #start the training process on all available GPUs\n                \n                mp.spawn(\n                    main_train,\n                    args=(world_size,),\n                    nprocs=world_size,\n                    join=True\n                )\n            else:\n                #run training on single GPU\n                main_train(rank=0, world_size=1)\n\n        else:\n            print('no GPUs found. Please make sure you have configured CUDA correctly')\n\n    main()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-09T00:26:25.776476Z","iopub.execute_input":"2025-01-09T00:26:25.776819Z","iopub.status.idle":"2025-01-09T00:26:25.784213Z","shell.execute_reply.started":"2025-01-09T00:26:25.776797Z","shell.execute_reply":"2025-01-09T00:26:25.783184Z"}},"outputs":[{"name":"stdout","text":"Overwriting main.py\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"!python main.py","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-09T00:26:37.988610Z","iopub.execute_input":"2025-01-09T00:26:37.988909Z","iopub.status.idle":"2025-01-09T00:28:44.643587Z","shell.execute_reply.started":"2025-01-09T00:26:37.988888Z","shell.execute_reply":"2025-01-09T00:28:44.642728Z"}},"outputs":[{"name":"stdout","text":"Total number of devices detected: 2\n[W109 00:26:44.246411498 socket.cpp:697] [c10d] The client socket has failed to connect to [localhost]:12345 (errno: 99 - Cannot assign requested address).\nProcess 1 initialized.\nProcess 0 initialized.\nNumber of training examples: 54000\nNumber of validation examples: 6000\nNumber of testing examples: 10000\nThe model has 222,360 trainable parameters\nThe model has 222,360 trainable parameters\nEpochs:   0%|          | 0/10 [00:00<?, ?it/s]\nEpochs:   0%|          | 0/10 [00:00<?, ?it/s]\nTraining on the rank 0...:   0%|          | 0/53 [00:00<?, ?it/s]\nTraining on the rank 1...:   0%|          | 0/53 [00:00<?, ?it/s]\n- On Training: 0 was passed over  53\n- On Training: 50 was passed over  53\nEvaluating on the rank 1 ...:   0%|          | 0/6 [00:00<?, ?it/s]\nEvaluating on the rank 0 ...:   0%|          | 0/6 [00:00<?, ?it/s]\n- On Evaluating: 0 was passed over  6\n--------------|     On process 1      |----------------\nEpoch: 01 | Epoch Time: 0m 12s\n\tTrain Loss: 1.021 | Train Acc: 68.40%\n\t Val. Loss: 0.623 |  Val. Acc: 81.13%\nTraining on the rank 1...:   0%|          | 0/53 [00:00<?, ?it/s]\n--------------|     On process 0      |----------------\nEpoch: 01 | Epoch Time: 0m 12s\n\tTrain Loss: 1.030 | Train Acc: 68.46%\n\t Val. Loss: 0.631 |  Val. Acc: 80.40%\nTraining on the rank 0...:   0%|          | 0/53 [00:00<?, ?it/s]\n- On Training: 0 was passed over  53\n- On Training: 50 was passed over  53\nEvaluating on the rank 1 ...:   0%|          | 0/6 [00:00<?, ?it/s]\nEvaluating on the rank 0 ...:   0%|          | 0/6 [00:00<?, ?it/s]\n- On Evaluating: 0 was passed over  6\n--------------|     On process 1      |----------------\nEpoch: 02 | Epoch Time: 0m 11s\n\tTrain Loss: 0.469 | Train Acc: 86.05%\n\t Val. Loss: 0.373 |  Val. Acc: 89.16%\nTraining on the rank 1...:   0%|          | 0/53 [00:00<?, ?it/s]\n--------------|     On process 0      |----------------\nEpoch: 02 | Epoch Time: 0m 11s\n\tTrain Loss: 0.463 | Train Acc: 86.36%\n\t Val. Loss: 0.379 |  Val. Acc: 88.80%\nTraining on the rank 0...:   0%|          | 0/53 [00:00<?, ?it/s]\n- On Training: 0 was passed over  53\n- On Training: 50 was passed over  53\nEvaluating on the rank 0 ...:   0%|          | 0/6 [00:00<?, ?it/s]\nEvaluating on the rank 1 ...:   0%|          | 0/6 [00:00<?, ?it/s]\n- On Evaluating: 0 was passed over  6\n--------------|     On process 1      |----------------\nEpoch: 03 | Epoch Time: 0m 11s\n\tTrain Loss: 0.294 | Train Acc: 91.25%\n\t Val. Loss: 0.257 |  Val. Acc: 93.17%\nTraining on the rank 1...:   0%|          | 0/53 [00:00<?, ?it/s]\n--------------|     On process 0      |----------------\nEpoch: 03 | Epoch Time: 0m 11s\n\tTrain Loss: 0.294 | Train Acc: 91.31%\n\t Val. Loss: 0.254 |  Val. Acc: 92.72%\nTraining on the rank 0...:   0%|          | 0/53 [00:00<?, ?it/s]\n- On Training: 0 was passed over  53\n- On Training: 50 was passed over  53\nEvaluating on the rank 0 ...:   0%|          | 0/6 [00:00<?, ?it/s]\nEvaluating on the rank 1 ...:   0%|          | 0/6 [00:00<?, ?it/s]\n- On Evaluating: 0 was passed over  6\n--------------|     On process 0      |----------------\nEpoch: 04 | Epoch Time: 0m 11s\n\tTrain Loss: 0.225 | Train Acc: 93.46%\n\t Val. Loss: 0.221 |  Val. Acc: 93.22%\nTraining on the rank 0...:   0%|          | 0/53 [00:00<?, ?it/s]\n--------------|     On process 1      |----------------\nEpoch: 04 | Epoch Time: 0m 11s\n\tTrain Loss: 0.221 | Train Acc: 93.54%\n\t Val. Loss: 0.209 |  Val. Acc: 93.90%\nTraining on the rank 1...:   0%|          | 0/53 [00:00<?, ?it/s]\n- On Training: 0 was passed over  53\n- On Training: 50 was passed over  53\nEvaluating on the rank 1 ...:   0%|          | 0/6 [00:00<?, ?it/s]\nEvaluating on the rank 0 ...:   0%|          | 0/6 [00:00<?, ?it/s]\n- On Evaluating: 0 was passed over  6\n--------------|     On process 1      |----------------\nEpoch: 05 | Epoch Time: 0m 11s\n\tTrain Loss: 0.183 | Train Acc: 94.62%\n\t Val. Loss: 0.174 |  Val. Acc: 94.65%\nTraining on the rank 1...:   0%|          | 0/53 [00:00<?, ?it/s]\n--------------|     On process 0      |----------------\nEpoch: 05 | Epoch Time: 0m 11s\n\tTrain Loss: 0.184 | Train Acc: 94.56%\n\t Val. Loss: 0.180 |  Val. Acc: 94.70%\nTraining on the rank 0...:   0%|          | 0/53 [00:00<?, ?it/s]\n- On Training: 0 was passed over  53\n- On Training: 50 was passed over  53\nEvaluating on the rank 1 ...:   0%|          | 0/6 [00:00<?, ?it/s]\nEvaluating on the rank 0 ...:   0%|          | 0/6 [00:00<?, ?it/s]\n- On Evaluating: 0 was passed over  6\n--------------|     On process 1      |----------------\nEpoch: 06 | Epoch Time: 0m 11s\n\tTrain Loss: 0.158 | Train Acc: 95.20%\n\t Val. Loss: 0.173 |  Val. Acc: 94.68%\nTraining on the rank 1...:   0%|          | 0/53 [00:00<?, ?it/s]\n--------------|     On process 0      |----------------\nEpoch: 06 | Epoch Time: 0m 11s\n\tTrain Loss: 0.164 | Train Acc: 95.14%\n\t Val. Loss: 0.171 |  Val. Acc: 94.83%\nTraining on the rank 0...:   0%|          | 0/53 [00:00<?, ?it/s]\n- On Training: 0 was passed over  53\n- On Training: 50 was passed over  53\nEvaluating on the rank 1 ...:   0%|          | 0/6 [00:00<?, ?it/s]\nEvaluating on the rank 0 ...:   0%|          | 0/6 [00:00<?, ?it/s]\n- On Evaluating: 0 was passed over  6\n--------------|     On process 0      |----------------\nEpoch: 07 | Epoch Time: 0m 11s\n\tTrain Loss: 0.143 | Train Acc: 95.90%\n\t Val. Loss: 0.157 |  Val. Acc: 95.02%\nTraining on the rank 0...:   0%|          | 0/53 [00:00<?, ?it/s]\n--------------|     On process 1      |----------------\nEpoch: 07 | Epoch Time: 0m 11s\n\tTrain Loss: 0.143 | Train Acc: 95.63%\n\t Val. Loss: 0.153 |  Val. Acc: 95.00%\nTraining on the rank 1...:   0%|          | 0/53 [00:00<?, ?it/s]\n- On Training: 0 was passed over  53\n- On Training: 50 was passed over  53\nEvaluating on the rank 1 ...:   0%|          | 0/6 [00:00<?, ?it/s]\nEvaluating on the rank 0 ...:   0%|          | 0/6 [00:00<?, ?it/s]\n- On Evaluating: 0 was passed over  6\n--------------|     On process 1      |----------------\nEpoch: 08 | Epoch Time: 0m 11s\n\tTrain Loss: 0.129 | Train Acc: 96.09%\n\t Val. Loss: 0.149 |  Val. Acc: 95.37%\nTraining on the rank 1...:   0%|          | 0/53 [00:00<?, ?it/s]\n--------------|     On process 0      |----------------\nEpoch: 08 | Epoch Time: 0m 11s\n\tTrain Loss: 0.136 | Train Acc: 96.08%\n\t Val. Loss: 0.137 |  Val. Acc: 96.55%\nTraining on the rank 0...:   0%|          | 0/53 [00:00<?, ?it/s]\n- On Training: 0 was passed over  53\n- On Training: 50 was passed over  53\nEvaluating on the rank 0 ...:   0%|          | 0/6 [00:00<?, ?it/s]\nEvaluating on the rank 1 ...:   0%|          | 0/6 [00:00<?, ?it/s]\n- On Evaluating: 0 was passed over  6\n--------------|     On process 0      |----------------\nEpoch: 09 | Epoch Time: 0m 11s\n\tTrain Loss: 0.125 | Train Acc: 96.30%\n\t Val. Loss: 0.129 |  Val. Acc: 96.01%\nTraining on the rank 0...:   0%|          | 0/53 [00:00<?, ?it/s]\n--------------|     On process 1      |----------------\nEpoch: 09 | Epoch Time: 0m 11s\n\tTrain Loss: 0.120 | Train Acc: 96.38%\n\t Val. Loss: 0.139 |  Val. Acc: 95.77%\nTraining on the rank 1...:   0%|          | 0/53 [00:00<?, ?it/s]\n- On Training: 0 was passed over  53\n- On Training: 50 was passed over  53\nEvaluating on the rank 1 ...:   0%|          | 0/6 [00:00<?, ?it/s]\nEvaluating on the rank 0 ...:   0%|          | 0/6 [00:00<?, ?it/s]\n- On Evaluating: 0 was passed over  6\n--------------|     On process 0      |----------------\nEpoch: 10 | Epoch Time: 0m 11s\n\tTrain Loss: 0.115 | Train Acc: 96.42%\n\t Val. Loss: 0.111 |  Val. Acc: 96.71%\n/kaggle/working/main.py:342: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  ddp_model.load_state_dict(torch.load(f'{root}mlp-model.pt'))\nTesting on the rank 0 ...:   0%|          | 0/20 [00:00<?, ?it/s]\n--------------|     On process 1      |----------------\nEpoch: 10 | Epoch Time: 0m 11s\n\tTrain Loss: 0.111 | Train Acc: 96.70%\n\t Val. Loss: 0.127 |  Val. Acc: 95.93%\n/kaggle/working/main.py:342: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  ddp_model.load_state_dict(torch.load(f'{root}mlp-model.pt'))\nTesting on the rank 1 ...:   0%|          | 0/20 [00:00<?, ?it/s]\n- On Testing: 0 was passed over  20\nTest results on process 0: Test Loss: 0.076 | Test Acc: 97.61%\nTest results on process 1: Test Loss: 0.076 | Test Acc: 97.61%\nProcess 0 finished training.\nProcess 1 finished training.\n","output_type":"stream"}],"execution_count":8}]}